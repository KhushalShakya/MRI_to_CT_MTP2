{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNmY5R5DGV3-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "import math\n",
    "import io\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
    "# device='cpu'\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import time\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import cv2\n",
    "import math\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/scai/mtech/aib222683/scratch/Task2/data'\n",
    "data_path_Train = os.path.join(path,'train') #Enter the train folder directory\n",
    "data_path_Test = os.path.join(path,'test') #Enter the test folder directory\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "\n",
    "\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "class MinMaxScale:\n",
    "    def __init__(self, min_val=0, max_val=1):\n",
    "        self.min = min_val\n",
    "        self.max = max_val\n",
    "        # print(self.min, self.max)\n",
    "\n",
    "    def __call__(self, img):\n",
    "         return (img-self.min)/(self.max-self.min)\n",
    "\n",
    "class MinMaxScaleInverse:\n",
    "    def __init__(self, min_val=0, max_val=1):\n",
    "        self.min = min_val\n",
    "        self.max = max_val\n",
    "        # print(self.min, self.max)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \n",
    "         return img*(self.max-self.min)+self.min\n",
    "         \n",
    "transform_train_x = transforms.Compose([Lambda(MinMaxScale(min_val=math.log(-3.1416+4), max_val=math.log(3677465+4)))])\n",
    "\n",
    "transform_train_y = transforms.Compose([Lambda(MinMaxScale(min_val=math.log(-3.1416+4), max_val=math.log(3677465+4)))])\n",
    "\n",
    "transform_test= transforms.Compose([Lambda(MinMaxScaleInverse(min_val=math.log(-3.1416+4), max_val=math.log(3677465+4)))])\n",
    "# min tensor(-3.1416)\n",
    "# max tensor(3677465.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for fourier\n",
    "def FCT(images):\n",
    "    # Convert RGB images to grayscale\n",
    "    # print(images.shape)\n",
    "    grayscale_images = np.mean(images, axis=-1)\n",
    "\n",
    "    # Compute the Fourier Transform for each image\n",
    "    data = np.fft.fft2(grayscale_images)\n",
    "\n",
    "    magnitude = np.abs(data)\n",
    "    phases = np.angle(data)\n",
    "\n",
    "    result_array = np.stack([magnitude, phases], axis=-1)\n",
    "\n",
    "    return result_array\n",
    "\n",
    "#function for inverse fourier\n",
    "def inverseFCT(img):\n",
    "    img=np.transpose(img,(1,2,0))\n",
    "    \n",
    "    magnitude=img[:,:,0]\n",
    "    phase=img[:,:,1]\n",
    "    # print(magnitude.shape)\n",
    "    complex_image = magnitude* np.exp(1j * phase)\n",
    "\n",
    "    # Perform the Inverse Fourier Transform\n",
    "    reconstructed_image = np.fft.ifft2(complex_image)\n",
    "\n",
    "    # Take the real part to get the original image\n",
    "    original_image = np.real(reconstructed_image)\n",
    "\n",
    "    return original_image\n",
    "\n",
    "\n",
    "def split(img):\n",
    "    return img[:,:,:,:256], img[:,:,:,256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create a class for training data containing both mri sequences (real and target) as a single merge image of shape (256,512)\n",
    "\n",
    "class MRIImage(Dataset):\n",
    "    def __init__(self, data_dir, transform1=None,transform2=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform1 = transform1\n",
    "        self.transform2=transform2\n",
    "        # self.transform3=transform3\n",
    "        self.image_paths =[os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, filename)) and not filename.startswith('.')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "        image =np.asarray(image)\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        img1=image[:,:256,:]\n",
    "        img2=image[:,256:,:]\n",
    "\n",
    "        img1=FCT(img1)\n",
    "        img2=FCT(img2)\n",
    "\n",
    "        img1=np.transpose(img1,(2,0,1))\n",
    "        img2=np.transpose(img2,(2,0,1))\n",
    "        \n",
    "        img1=torch.from_numpy(img1).float()\n",
    "        img2=torch.from_numpy(img2).float()\n",
    "        \n",
    "        img1=torch.log(img1+4)\n",
    "        img2=torch.log(img2+4)\n",
    "        \n",
    "        if self.transform1:\n",
    "            img1= self.transform1(img1)\n",
    "            \n",
    "        if self.transform2:\n",
    "            img2=self.transform2(img2)\n",
    "            \n",
    "        image=torch.cat((img1, img2), dim=2)\n",
    "        \n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIImageTest(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, filename)) and not filename.startswith('.')]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "full_dataset =MRIImage(data_dir=data_path_Train, transform1=transform_train_x,transform2=transform_train_y)\n",
    "\n",
    "train_dataset=full_dataset\n",
    "# Create a data loader for training\n",
    "load_Train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bv7QmQJVJ-nS"
   },
   "outputs": [],
   "source": [
    "# Load the entire test dataset\n",
    "full_test_dataset = MRIImage(data_dir=data_path_Test, transform1=transform_train_x,transform2=transform_train_y)\n",
    "\n",
    "test_dataset=full_test_dataset\n",
    "# Create a data loader for testing\n",
    "load_Test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_x5GZanHxVG"
   },
   "outputs": [],
   "source": [
    "inst_norm = True if batch_size==1 else False  # instance normalization\n",
    "\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride,\n",
    "    padding=padding)\n",
    "\n",
    "\n",
    "def conv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, inst_norm=False):\n",
    "    if inst_norm == True:\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding), nn.InstanceNorm2d(out_channels,\n",
    "        momentum=0.1, eps=1e-5),)\n",
    "    else:\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding), nn.BatchNorm2d(out_channels,\n",
    "        momentum=0.1, eps=1e-5),)\n",
    "\n",
    "def tconv(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0,):\n",
    "    return nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride,\n",
    "    padding=padding, output_padding=output_padding)\n",
    "\n",
    "def tconv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, inst_norm=False):\n",
    "    if inst_norm == True:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding, output_padding=output_padding),\n",
    "        nn.InstanceNorm2d(out_channels, momentum=0.1, eps=1e-5),)\n",
    "    else:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding, output_padding=output_padding),\n",
    "        nn.BatchNorm2d(out_channels, momentum=0.1, eps=1e-5),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IdmxqS_Icku"
   },
   "outputs": [],
   "source": [
    "dim_c = 2\n",
    "dim_g = 64\n",
    "\n",
    "# Generator\n",
    "class Gen(nn.Module):\n",
    "    def __init__(self, inst_norm=False):\n",
    "        super(Gen,self).__init__()\n",
    "        self.n1 = conv(dim_c, dim_g, 4, 2, 1)\n",
    "        self.n2 = conv_n(dim_g, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n3 = conv_n(dim_g*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n4 = conv_n(dim_g*4, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n5 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n6 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n7 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n8 = conv(dim_g*8, dim_g*8, 4, 2, 1)\n",
    "\n",
    "        self.m1 = tconv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m2 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m3 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m4 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m5 = tconv_n(dim_g*8*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m6 = tconv_n(dim_g*4*2, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m7 = tconv_n(dim_g*2*2, dim_g*1, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m8 = tconv(dim_g*1*2, dim_c, 4, 2, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self,x):\n",
    "        n1 = self.n1(x)\n",
    "        n2 = self.n2(F.leaky_relu(n1, 0.2))\n",
    "        n3 = self.n3(F.leaky_relu(n2, 0.2))\n",
    "        n4 = self.n4(F.leaky_relu(n3, 0.2))\n",
    "        n5 = self.n5(F.leaky_relu(n4, 0.2))\n",
    "        n6 = self.n6(F.leaky_relu(n5, 0.2))\n",
    "        n7 = self.n7(F.leaky_relu(n6, 0.2))\n",
    "        n8 = self.n8(F.leaky_relu(n7, 0.2))\n",
    "        m1 = torch.cat([F.dropout(self.m1(F.relu(n8)), 0.5, training=True), n7], 1)\n",
    "        m2 = torch.cat([F.dropout(self.m2(F.relu(m1)), 0.5, training=True), n6], 1)\n",
    "        m3 = torch.cat([F.dropout(self.m3(F.relu(m2)), 0.5, training=True), n5], 1)\n",
    "        m4 = torch.cat([self.m4(F.relu(m3)), n4], 1)\n",
    "        m5 = torch.cat([self.m5(F.relu(m4)), n3], 1)\n",
    "        m6 = torch.cat([self.m6(F.relu(m5)), n2], 1)\n",
    "        m7 = torch.cat([self.m7(F.relu(m6)), n1], 1)\n",
    "        m8 = self.m8(F.relu(m7))\n",
    "\n",
    "        return self.tanh(m8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eds_dHD5IfYB"
   },
   "outputs": [],
   "source": [
    "dim_d = 64\n",
    "\n",
    "# Discriminator\n",
    "class Disc(nn.Module):\n",
    "    def __init__(self, inst_norm=False):\n",
    "        super(Disc,self).__init__()\n",
    "        self.c1 = conv(dim_c*2, dim_d, 4, 2, 1)\n",
    "        self.c2 = conv_n(dim_d, dim_d*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.c3 = conv_n(dim_d*2, dim_d*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.c4 = conv_n(dim_d*4, dim_d*8, 4, 1, 1, inst_norm=inst_norm)\n",
    "        self.c5 = conv(dim_d*8, 1, 4, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        xy=torch.cat([x,y],dim=1)\n",
    "        xy=F.leaky_relu(self.c1(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c2(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c3(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c4(xy), 0.2)\n",
    "        xy=self.c5(xy)\n",
    "\n",
    "        return self.sigmoid(xy)\n",
    "\n",
    "def weights_init(z):\n",
    "    cls_name =z.__class__.__name__\n",
    "    if cls_name.find('Conv')!=-1 or cls_name.find('Linear')!=-1:\n",
    "        nn.init.normal_(z.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(z.bias.data, 0)\n",
    "    elif cls_name.find('BatchNorm')!=-1:\n",
    "        nn.init.normal_(z.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(z.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1ffYi1eIi7E"
   },
   "outputs": [],
   "source": [
    "BCE = nn.BCELoss() #binary cross-entropy\n",
    "L1 = nn.L1Loss()\n",
    "L2=nn.MSELoss()\n",
    "#instance normalization\n",
    "Gen_model = Gen(inst_norm).to(device)\n",
    "Disc = Disc(inst_norm).to(device)\n",
    "generator = Gen(inst_norm).to(device)\n",
    "#optimizers\n",
    "# Gen_optim = optim.Adam(Gen.parameters(), lr=2e-4, betas=(0.5, 0.999), weight_decay=0.35)\n",
    "Gen_optim = optim.Adam(Gen_model.parameters(), lr=1e-4, betas=(0.5, 0.999))   #lr=2e-3\n",
    "Disc_optim = optim.Adam(Disc.parameters(), lr=5e-5, betas=(0.5, 0.999))   # lr=2e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "qLH0qjIsIoJi",
    "outputId": "05351d34-f0c9-4d4c-a1f9-ae205b54d496"
   },
   "outputs": [],
   "source": [
    "# # img_list = []\n",
    "# Disc_losses = Gen_losses = Gen_GAN_losses = Gen_L1_losses = []\n",
    "\n",
    "\n",
    "min_value=math.log(-3.1416+4)\n",
    "max_value=math.log(3677465+4)\n",
    "# min_value=(-3.1416)\n",
    "# max_value=(4239579)\n",
    "\n",
    "iter_per_plot = 20\n",
    "epochs = 30\n",
    "L1_lambda = 50.0\n",
    "\n",
    "\n",
    "for ep in range(epochs):\n",
    "    for i, data in enumerate(load_Train):\n",
    "        size = data.shape[0]\n",
    "\n",
    "        x, y = split(data.to(device))\n",
    "\n",
    "        r_masks = torch.ones(size,1,30,30).to(device)\n",
    "        f_masks = torch.zeros(size,1,30,30).to(device)\n",
    "\n",
    "        fake=Gen_model(x)\n",
    "        # disc\n",
    "        if (ep+1)%2!=0:\n",
    "            Disc.zero_grad()\n",
    "            r_patch=Disc(y,x)\n",
    "    \n",
    "            # print(r_patch.mean())\n",
    "            \n",
    "            # print(r_patch.mean())\n",
    "            r_disc_loss=L2(r_patch,r_masks)\n",
    "            # print(r_gan_loss)\n",
    "            \n",
    "    \n",
    "            \n",
    "            #fake_patch\n",
    "            f_patch = Disc(fake.detach(),x)\n",
    "            f_disc_loss=L2(f_patch,f_masks)\n",
    "            Disc_loss = r_disc_loss + f_disc_loss\n",
    "           \n",
    "            Disc_loss.backward()\n",
    "            Disc_optim.step()\n",
    "\n",
    "        # gen\n",
    "        # fake=Gen_model(x)\n",
    "        Gen_model.zero_grad()\n",
    "        f_patch = Disc(fake,x)\n",
    "        f_gan_loss=L2(f_patch,r_masks)\n",
    "\n",
    "        L1_loss = L1(fake,y)\n",
    "        Gen_loss = f_gan_loss + L1_lambda*L1_loss\n",
    "        # print(Gen_loss.item())\n",
    "        Gen_loss.backward()\n",
    "\n",
    "        Gen_optim.step()\n",
    "        \n",
    "        \n",
    "        if (i+1)%iter_per_plot == 0 :\n",
    "            if (ep+1)%2!=0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], disc_loss: {:.4f}, gen_loss: {:.4f},Disc(real): {:.2f}, Disc(fake):{:.2f}, gen_loss_gan:{:.4f}, gen_loss_L1:{:.4f}'.format(ep+1, epochs, i+1, len(load_Train), Disc_loss.item(), Gen_loss.item(), r_disc_loss.item(), f_disc_loss.item(), f_gan_loss.item(), L1_loss.item()))\n",
    "            else:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], disc_loss: {:.4f}, gen_loss: {:.4f},Disc(real): {:.2f}, Disc(fake):{:.2f}, gen_loss_gan:{:.4f}, gen_loss_L1:{:.4f}'.format(ep+1, epochs, i+1, len(load_Train), 0, Gen_loss.item(), 0, 0, f_gan_loss.item(), L1_loss.item()))\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "    if (ep+1)==epochs:\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            Gen_model.eval()\n",
    "            for data in load_Train:\n",
    "                # print(data.shape)\n",
    "                x, y = split(data.to(device))\n",
    "                fake = Gen_model(x)\n",
    "                for j in range(fake.shape[0]):\n",
    "                    if j%10==0:\n",
    "                        t_y=y[j].cpu().detach().numpy()\n",
    "                        fk_batch=fake[j].cpu().detach().numpy()\n",
    "                        t_x=x[j].cpu().detach().numpy()\n",
    "                        \n",
    "                        t_x=t_x*(max_value-min_value)+min_value\n",
    "                        t_y=t_y*(max_value-min_value)+min_value\n",
    "                        fk_batch=fk_batch*(max_value-min_value)+min_value\n",
    "                        \n",
    "                        t_x=np.exp(t_x)-4\n",
    "                        t_y=np.exp(t_y)-4\n",
    "                        fk_batch=np.exp(fk_batch)-4\n",
    "                        \n",
    "                        t_x=inverseFCT(t_x)\n",
    "                        t_y=inverseFCT(t_y)\n",
    "                        fk_batch=inverseFCT(fk_batch)\n",
    "                        \n",
    "                        plt.figure(figsize=(10, 4))\n",
    "                        \n",
    "                        # Plotting the first array\n",
    "                        plt.subplot(1, 3, 1)\n",
    "                        plt.imshow(t_x)\n",
    "                        plt.title('input')\n",
    "                        \n",
    "                        # Plotting the second array\n",
    "                        plt.subplot(1, 3, 2)\n",
    "                        plt.imshow(fk_batch)\n",
    "                        plt.title('generated image')\n",
    "                        \n",
    "                        # Plotting the third array\n",
    "                        plt.subplot(1, 3, 3)\n",
    "                        plt.imshow(t_y)\n",
    "                        plt.title('ground truth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n",
    "                break\n",
    "            Gen_model.train()\n",
    "            \n",
    "    if ep+1==epochs:\n",
    "        torch.save(Gen_model.state_dict(), 'MRI2CT_fourier_30epoch.pth')  \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "B82wtNwZI3SD",
    "outputId": "d36cb8c6-4eef-4f69-e5a9-d72078d676bf"
   },
   "outputs": [],
   "source": [
    "# t_batch =  next(iter(load_Test))\n",
    "# # print(t_batch.shape)\n",
    "# t_x, t_y = split(t_batch)\n",
    "error_list=[]\n",
    "generator.load_state_dict(torch.load(\"MRI2CT_fourier_30epoch.pth\", map_location=device))\n",
    "\n",
    "batch_size = 1  # Set the batch size to 1 to get a single image in each iteration\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    t_batch=data\n",
    "    t_x, t_y = split(t_batch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        fk_batch=generator(t_x.to(device))\n",
    "    t_y=t_y.numpy()\n",
    "    fk_batch=fk_batch.cpu().detach().numpy()\n",
    "    t_y=t_y*(max_value-min_value)+min_value\n",
    "    fk_batch=fk_batch*(max_value-min_value)+min_value\n",
    "\n",
    "    t_y=np.exp(t_y.squeeze())-4\n",
    "    fk_batch=np.exp(fk_batch.squeeze())-4\n",
    "\n",
    "    # t_x=(t_x.squeeze())\n",
    "    # t_y=(t_y.squeeze())\n",
    "    # fk_batch=(fk_batch.squeeze())\n",
    "    \n",
    "    \n",
    "    t_y=inverseFCT(t_y)\n",
    "    fk_batch=inverseFCT(fk_batch)\n",
    "    \n",
    "    # print(t_y.shape,fk_batch.shape)\n",
    "    error_list.append(np.sqrt(np.sum((t_y-fk_batch)**2)))\n",
    "    \n",
    "\n",
    "error_list=np.array(error_list)\n",
    "\n",
    "\n",
    "print('mean rmse error :',np.mean(error_list))\n",
    "print('max rmse error:',np.max(error_list))\n",
    "print('min rmse error:',np.min(error_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_visual(img):\n",
    "    \n",
    "    img=np.transpose(img,(1,2,0))\n",
    "    \n",
    "    magnitude=img[:,:,0]\n",
    "    phase=img[:,:,1]\n",
    "\n",
    "    magnitude_log = np.log1p(magnitude)\n",
    "\n",
    "    normalized_magnitude=Normalize()(magnitude_log)\n",
    "    # print(np.max(normalized_magnitude),np.min(normalized_magnitud?\n",
    "\n",
    "    return normalized_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value=math.log(-3.1416+4)\n",
    "max_value=math.log(3677465+4)\n",
    "\n",
    "# min_value=(-3.1416)\n",
    "# max_value=(4239579)\n",
    "c=0\n",
    "for data in (test_loader):\n",
    "    t_batch=data\n",
    "    t_x, t_y = split(t_batch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        fk_batch=generator(t_x.to(device))\n",
    "    t_y=t_y.numpy()\n",
    "    fk_batch=fk_batch.cpu().detach().numpy()\n",
    "    t_x=t_x.cpu().detach().numpy()\n",
    "    \n",
    "    t_x=t_x*(max_value-min_value)+min_value\n",
    "    t_y=t_y*(max_value-min_value)+min_value\n",
    "    fk_batch=fk_batch*(max_value-min_value)+min_value\n",
    "    \n",
    "    t_x=np.exp(t_x.squeeze())-4.5\n",
    "    t_y=np.exp(t_y.squeeze())-4.5\n",
    "    fk_batch=np.exp(fk_batch.squeeze())-4.5\n",
    "\n",
    "    # fft_visual(fk_batch)\n",
    "   \n",
    "    mag_t_x=fft_visual(t_x)\n",
    "    mag_t_y=fft_visual(t_y)\n",
    "    mag_fk_batch=fft_visual(fk_batch)\n",
    "    \n",
    "   \n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # Plotting the first array\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(mag_t_x,cmap='gray')\n",
    "    plt.title('log magnitude(input)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plotting the second array\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mag_fk_batch,cmap='gray')\n",
    "    plt.title('log magnitude(generated image)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plotting the third array\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(mag_t_y,cmap='gray')\n",
    "    plt.title('log magnitude(ground truth)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    c+=1\n",
    "# # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    if c==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_value=math.log(-3.1416+4)\n",
    "# max_value=math.log(3677465+4)\n",
    "\n",
    "c=0\n",
    "for data in tqdm(test_loader):\n",
    "    t_batch=data\n",
    "    t_x, t_y = split(t_batch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        fk_batch=generator(t_x.to(device))\n",
    "    t_y=t_y.numpy()\n",
    "    fk_batch=fk_batch.cpu().detach().numpy()\n",
    "    t_x=t_x.cpu().detach().numpy()\n",
    "    \n",
    "    t_x=t_x*(max_value-min_value)+min_value\n",
    "    t_y=t_y*(max_value-min_value)+min_value\n",
    "    fk_batch=fk_batch*(max_value-min_value)+min_value\n",
    "    \n",
    "    t_x=np.exp(t_x.squeeze())-4\n",
    "    t_y=np.exp(t_y.squeeze())-4\n",
    "    fk_batch=np.exp(fk_batch.squeeze())-4\n",
    "\n",
    "    # t_x=(t_x.squeeze())\n",
    "    # t_y=(t_y.squeeze())\n",
    "    # fk_batch=(fk_batch.squeeze())\n",
    "    \n",
    "    t_x=inverseFCT(t_x)\n",
    "    t_y=inverseFCT(t_y)\n",
    "    fk_batch=inverseFCT(fk_batch)\n",
    "\n",
    "\n",
    "\n",
    "    normalized_t_x=Normalize()(t_x)\n",
    "    normalized_fk_batch=Normalize()(fk_batch)\n",
    "    normalized_t_y=Normalize()(t_y)\n",
    "    # print(np.max(normalized_fk_batch),np.min(normalized_fk_batch))\n",
    "    # print(np.max(normalized_t_y),np.min(normalized_t_y))\n",
    "\n",
    "    # print(np.max(fk_batch),np.min(fk_batch))\n",
    "    # print(np.max(t_y),np.min(t_y))\n",
    "    # print('#############################')\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # Plotting the first array\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow( normalized_t_x,cmap='gray')\n",
    "    plt.title('input')\n",
    "    plt.axis('off')\n",
    "    # Plotting the second array\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow( normalized_fk_batch,cmap='gray')\n",
    "    plt.title('generated image')\n",
    "    plt.axis('off')\n",
    "    # Plotting the third array\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow( normalized_t_y,cmap='gray')\n",
    "    plt.title('ground truth')\n",
    "    plt.axis('off')\n",
    "    c+=1\n",
    "\n",
    "# Show the plots\n",
    "    # plt.show()\n",
    "\n",
    "    # print(np.max(t_x),np.min(t_x))\n",
    "    # print(np.max(t_y),np.min(t_y))\n",
    "    # print(np.max(fk_batch),np.min(fk_batch))\n",
    "    if c==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_batch =  next(iter(load_Test))\n",
    "# # print(t_batch.shape)\n",
    "# t_x, t_y = split(t_batch)\n",
    "\n",
    "# # generator.load_state_dict(torch.load('t1_to_t2_model_gaussian.pth', map_location=device))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     generator.eval()\n",
    "#     fk=generator(t_x.to(device))\n",
    "#     t_y=t_y.to(device)\n",
    "#     # print(fk.shape)\n",
    "# # compare_batches(t_x, fk_batch, t_y,\"input images\", \"predicted images\",  \"ground truth\")\n",
    "# for j in range(fk.shape[0]):\n",
    "#     if j%3==0:\n",
    "#         figs=plt.figure(figsize=(12,8))\n",
    "#         plt.subplot(1,2,1)\n",
    "#         fake_np_rgb=np.transpose((fk[j].cpu().numpy()),(1,2,0))\n",
    "#         fake_np_rgb=Normalize()(fake_np_rgb)\n",
    "#         fake_np_gray=np.mean(fake_np_rgb, axis=2)\n",
    "#         # fake_np_gray= (fake_np_gray*255).astype(np.uint8)\n",
    "#         # print(fake_np_gray.shape)\n",
    "#         # pixel_values = fake_np_gray.flatten()\n",
    "#         # print(pixel_values.shape\n",
    "# # Plot the histogram\n",
    "#         plt.hist(fake_np_gray.flatten(), bins=256, range=[0, 1], density=True, color='red', alpha=0.5)\n",
    "#         plt.yscale('log')\n",
    "#         plt.xlabel('Intensity Value')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.title('Histogram of Grayscale Generated Image (Intensity [0, 1])')\n",
    "#         # plt.show()\n",
    "#         # figs=plt.figure(figsize=(10,10))\n",
    "#         plt.subplot(1,2,2)\n",
    "#         true_np_rgb=np.transpose((t_y[j].cpu().numpy()),(1,2,0))\n",
    "#         true_np_rgb=Normalize()(true_np_rgb)\n",
    "#         true_np_gray=np.mean(true_np_rgb, axis=2)\n",
    "# # Plot the histogram\n",
    "#         plt.hist(true_np_gray.flatten(), bins=256, range=[0, 1], density=True, color='gray', alpha=0.5)\n",
    "#         plt.yscale('log')\n",
    "#         plt.xlabel('Intensity Value')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.title('Histogram of Grayscale True Image (Intensity [0, 1])')\n",
    "#         plt.show()\n",
    "        # plt.axis(\"off\")\n",
    "        # plt.title(\"generated image histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nksbEj7paRzo"
   },
   "outputs": [],
   "source": [
    "# # Assuming you have a dataset called 'test_dataset'\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Now you can iterate over it with random samples\n",
    "# for _ in range(20):\n",
    "#     t_batch, _ = next(iter(test_loader))\n",
    "#     t_x, t_y = split(t_batch)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         Gen.eval()\n",
    "#         fk_batch = Gen(t_x.to(device))\n",
    "\n",
    "#     compare_batches(t_x, fk_batch, t_y, \"input images\", \"predicted images\", \"ground truth\")\n",
    "#     # compare_batches(t_x, fk_batch, \"input images\", \"predicted images\", t_y, \"ground truth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "71qX34-Ia-_5",
    "outputId": "3f96d0c7-562a-49c8-bc03-ce96105432a6"
   },
   "outputs": [],
   "source": [
    "# # Assuming you have a dataset called 'test_dataset'\n",
    "# batch_size = 1  # Set the batch size to 1 to get a single image in each iteration\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# error_list=[]\n",
    "# structural_similarity=[]\n",
    "# # Now you can iterate over it with random samples\n",
    "# for i,data in enumerate (test_loader):\n",
    "#     t_batch=data\n",
    "#     t_x, t_y = split(t_batch)\n",
    "#     with torch.no_grad():\n",
    "#         generator.eval()\n",
    "#         fk_batch = generator(t_x.to(device))\n",
    "#     # if i%10==0:\n",
    "#     #     compare_batches(t_x, fk_batch, t_y, \"input images\", \"predicted images\",\"ground truth\")\n",
    "#     t_y=t_y.numpy()\n",
    "#     fk_batch=fk_batch.cpu().detach().numpy()\n",
    "#     # print(t_y.shape)\n",
    "#     # print(fk_batch.shape)\n",
    "#     error_list.append(np.sqrt(np.sum((t_y-fk_batch)**2)))\n",
    "#     t_y=np.transpose(t_y.squeeze(), (1, 2, 0))\n",
    "#     fk_batch=np.transpose(fk_batch.squeeze(), (1, 2, 0))\n",
    "#     # print(np.min(t_y))\n",
    "#     # print(np.max(t_y))\n",
    "#     # # print(fk_batch.shape)\n",
    "#     ssi=ssim(t_y,fk_batch,multichannel=True,win_size=3,data_range=2.0)\n",
    "#     structural_similarity.append(ssi)\n",
    "#     # print(error_list)\n",
    "# error_list=np.array(error_list)\n",
    "# structural_similarity_np=np.array(structural_similarity)\n",
    "\n",
    "# print('mean rmse error :',np.mean(error_list))\n",
    "# print('max rmse error:',np.max(error_list))\n",
    "# print('min rmse error:',np.min(error_list))\n",
    "# print('mean ssim :',np.mean(structural_similarity_np))\n",
    "# print('min ssim :',np.min(structural_similarity_np))\n",
    "# print('max ssim :',np.max(structural_similarity_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59uEf4fleo_R"
   },
   "outputs": [],
   "source": [
    "# for i,data in enumerate (test_loader):\n",
    "#     t_batch=data\n",
    "#     t_x, t_y = split(t_batch)\n",
    "#     with torch.no_grad():\n",
    "#         generator.eval()\n",
    "#         fk_batch = generator(t_x.to(device))\n",
    "#     if structural_similarity[i]>np.mean(structural_similarity_np):\n",
    "#         # print(i)\n",
    "#         compare_batches(t_x, fk_batch, t_y, \"input images\", \"predicted images\",\"ground truth\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZeB82-0cXv1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
