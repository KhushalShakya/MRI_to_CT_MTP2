{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNmY5R5DGV3-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "import math\n",
    "import io\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
    "# device='cpu'\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import time\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "import random\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import cv2\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training and testing we have load image that is merge of both input and target (256,512)\n",
    "path='/home/scai/mtech/aib222677/scratch/data'\n",
    "path1='/home/scai/mtech/aib222683/scratch/Task2/data'\n",
    "# data_path_Train = os.path.join(path,'train') #Enter the train folder directory\n",
    "# data_path_Test = os.path.join(path,'test') #Enter the test folder directory\n",
    "data_path_Train = os.path.join(path1,'train')\n",
    "data_path_Test = os.path.join(path1,'test')\n",
    "\n",
    "batch_size = 30\n",
    "num_workers = 2 \n",
    "transform_train_x = transforms.Compose([transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "                                                                   \n",
    "transform_train_y = transforms.Compose([transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "transform= transforms.Compose([transforms.Resize((256,512)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainImage(Dataset):\n",
    "    def __init__(self, data_dir, transform1=None,transform2=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform1 = transform1\n",
    "        self.transform2 = transform2\n",
    "        self.image_paths = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        to_tensor=transforms.ToTensor()\n",
    "        image=to_tensor(image)\n",
    "\n",
    "        img1=image[:,:,:256]\n",
    "        img2=image[:,:,256:]\n",
    "        \n",
    "        \n",
    "        if self.transform1:\n",
    "            img1 = self.transform1(img1)\n",
    "            \n",
    "        if self.transform2:\n",
    "            img2 = self.transform2(img2)\n",
    "\n",
    "        image=torch.cat((img1,img2),dim=2)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainImageTest(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, filename)) and not filename.startswith('.')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "\n",
    "# Load the entire training dataset\n",
    "full_dataset=BrainImage(data_dir=data_path_Train, transform1=transform_train_x,transform2=transform_train_y)\n",
    "train_dataset=full_dataset\n",
    "# Create a data loader for training\n",
    "load_Train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bv7QmQJVJ-nS"
   },
   "outputs": [],
   "source": [
    "# Load the entire test dataset\n",
    "full_test_dataset = BrainImageTest(data_dir=data_path_Test, transform=transform)\n",
    "\n",
    "test_dataset=full_test_dataset\n",
    "\n",
    "# Create a data loader for testing\n",
    "load_Test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEsnqfLuKHEe",
    "outputId": "044ca266-d90b-42a2-8e1b-9d5b914472ec"
   },
   "outputs": [],
   "source": [
    "#function used to split input and target\n",
    "def split(img):\n",
    "    return img[:,:,:,:256], img[:,:,:,256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_x5GZanHxVG"
   },
   "outputs": [],
   "source": [
    "inst_norm = True if batch_size==1 else False  # instance normalization\n",
    "\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride,\n",
    "    padding=padding)\n",
    "\n",
    "\n",
    "def conv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, inst_norm=False):\n",
    "    if inst_norm == True:\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding), nn.InstanceNorm2d(out_channels,\n",
    "        momentum=0.1, eps=1e-5),)\n",
    "    else:\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding), nn.BatchNorm2d(out_channels,\n",
    "        momentum=0.1, eps=1e-5),)\n",
    "\n",
    "def tconv(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0,):\n",
    "    return nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride,\n",
    "    padding=padding, output_padding=output_padding)\n",
    "\n",
    "def tconv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, inst_norm=False):\n",
    "    if inst_norm == True:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding, output_padding=output_padding),\n",
    "        nn.InstanceNorm2d(out_channels, momentum=0.1, eps=1e-5),)\n",
    "    else:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding, output_padding=output_padding),\n",
    "        nn.BatchNorm2d(out_channels, momentum=0.1, eps=1e-5),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_c = 3\n",
    "dim_g = 64\n",
    "\n",
    "# Generator class designed for taking input of shape (128,128,3)\n",
    "class Gen(nn.Module):\n",
    "    def __init__(self, inst_norm=False):\n",
    "        super(Gen,self).__init__()\n",
    "        self.n1 = conv(dim_c, dim_g, 4, 2, 1)\n",
    "        self.n2 = conv_n(dim_g, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n3 = conv_n(dim_g*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n4 = conv_n(dim_g*4, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n5 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n6 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n7 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        # self.n8 = conv(dim_g*8, dim_g*8, 4, 2, 1)\n",
    "\n",
    "        self.m1 = tconv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m2 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m3 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m4 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m5 = tconv_n(dim_g*8+256, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m6 = tconv_n(dim_g*4+128, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m7 = tconv_n(dim_g*2+64, dim_c, 4, 2, 1, inst_norm=inst_norm)\n",
    "        # self.m8 = tconv(dim_g*1*2, dim_c, 4, 2, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self,x):\n",
    "        n1 = self.n1(x)\n",
    "        n2 = self.n2(F.leaky_relu(n1, 0.2))\n",
    "        n3 = self.n3(F.leaky_relu(n2, 0.2))\n",
    "        n4 = self.n4(F.leaky_relu(n3, 0.2))\n",
    "        n5 = self.n5(F.leaky_relu(n4, 0.2))\n",
    "        n6 = self.n6(F.leaky_relu(n5, 0.2))\n",
    "        n7 = self.n7(F.leaky_relu(n6, 0.2))\n",
    "       \n",
    "        m1 = torch.cat([F.dropout(self.m1(F.relu(n7)), 0.5, training=True), n6], 1)\n",
    "        \n",
    "        m2 = torch.cat([F.dropout(self.m2(F.relu(m1)), 0.5, training=True), n5], 1)\n",
    "        \n",
    "        m3 = torch.cat([F.dropout(self.m3(F.relu(m2)), 0.5, training=True), n4], 1)\n",
    "        \n",
    "        m4 = torch.cat([self.m4(F.relu(m3)), n3], 1)\n",
    "       \n",
    "        m5 = torch.cat([self.m5(F.relu(m4)), n2], 1)\n",
    "       \n",
    "        m6 = torch.cat([self.m6(F.relu(m5)), n1], 1)\n",
    "       \n",
    "        m7 = self.m7(F.relu(m6))\n",
    "       \n",
    "        return self.tanh(m7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_d = 64\n",
    "\n",
    "#  discriminator class designed for taking input of shape (128,128,3)\n",
    "class Disc(nn.Module):\n",
    "    def __init__(self, inst_norm=False):\n",
    "        super(Disc,self).__init__()\n",
    "        self.c1 = conv(dim_c*2, dim_d, 4, 2, 1)\n",
    "        self.c2 = conv_n(dim_d, dim_d*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.c4 = conv_n(dim_d*2, dim_d*4, 4, 1, 1, inst_norm=inst_norm)\n",
    "        self.c5 = conv(dim_d*4, 1, 4, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        xy=torch.cat([x,y],dim=1)\n",
    "       \n",
    "        xy=F.leaky_relu(self.c1(xy), 0.2)\n",
    "        \n",
    "        xy=F.leaky_relu(self.c2(xy), 0.2)\n",
    "        \n",
    "        xy=F.leaky_relu(self.c4(xy), 0.2)\n",
    "        \n",
    "        xy=self.c5(xy)\n",
    "\n",
    "        return self.sigmoid(xy)\n",
    "\n",
    "def weights_init(z):\n",
    "    cls_name =z.__class__.__name__\n",
    "    if cls_name.find('Conv')!=-1 or cls_name.find('Linear')!=-1:\n",
    "        nn.init.normal_(z.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(z.bias.data, 0)\n",
    "    elif cls_name.find('BatchNorm')!=-1:\n",
    "        nn.init.normal_(z.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(z.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1ffYi1eIi7E"
   },
   "outputs": [],
   "source": [
    "BCE = nn.BCELoss() #binary cross-entropy\n",
    "L1 = nn.L1Loss() # L1 loss\n",
    "L2=nn.MSELoss() # L2 loss\n",
    "#instance normalization\n",
    "Gen_model = Gen(inst_norm).to(device)\n",
    "Disc = Disc(inst_norm).to(device)\n",
    "generator = Gen(inst_norm).to(device)\n",
    "#optimizers\n",
    "# Gen_optim = optim.Adam(Gen.parameters(), lr=2e-4, betas=(0.5, 0.999), weight_decay=0.35)\n",
    "Gen_optim = optim.Adam(Gen_model.parameters(), lr=2e-4, betas=(0.5, 0.999))   #lr=1e-4\n",
    "Disc_optim = optim.Adam(Disc.parameters(), lr=2e-4, betas=(0.5, 0.999))   # lr=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "qLH0qjIsIoJi",
    "outputId": "05351d34-f0c9-4d4c-a1f9-ae205b54d496"
   },
   "outputs": [],
   "source": [
    "# training and displaying the results of training on few training samples\n",
    "\n",
    "\n",
    "iter_per_plot = 10\n",
    "epochs = 10\n",
    "L1_lambda = 100.0\n",
    "\n",
    "\n",
    "for ep in range(epochs):\n",
    "    for i, data in enumerate(load_Train):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        size = data.shape[0]\n",
    "        # creating patches from input image \n",
    "        x1,y1=[],[]\n",
    "        x2,y2=[],[]\n",
    "        x3,y3=[],[]\n",
    "        x4,y4=[],[]\n",
    "        x5,y5=[],[]\n",
    "        x_img, y_img= split(data.to(device))\n",
    "\n",
    "        for img in x_img:\n",
    "          x1.append(img[:,:128,:128])\n",
    "          x2.append(img[:,128:,:128])\n",
    "          x3.append(img[:,:128,128:])\n",
    "          x4.append(img[:,128:,128:])\n",
    "          x5.append(img[:,64:192,64:192])\n",
    "\n",
    "        for img in y_img:\n",
    "          y1.append(img[:,:128,:128])\n",
    "          y2.append(img[:,128:,:128])\n",
    "          y3.append(img[:,:128,128:])\n",
    "          y4.append(img[:,128:,128:])\n",
    "          y5.append(img[:,64:192,64:192])\n",
    "\n",
    "        \n",
    "        input=[]\n",
    "\n",
    "        input.append((torch.stack(x1),torch.stack(y1)))\n",
    "        input.append((torch.stack(x2),torch.stack(y2)))\n",
    "        input.append((torch.stack(x3),torch.stack(y3)))\n",
    "        input.append((torch.stack(x4),torch.stack(y4)))\n",
    "        input.append((torch.stack(x5),torch.stack(y5)))\n",
    "\n",
    "       \n",
    "\n",
    "        for x,y in input:\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "            r_masks = torch.ones(size,1,30,30).to(device)\n",
    "            f_masks = torch.zeros(size,1,30,30).to(device)\n",
    "    \n",
    "            # disc\n",
    "            Disc.zero_grad()\n",
    "            r_patch=Disc(y,x)\n",
    "           \n",
    "            \n",
    "            \n",
    "            r_disc_loss=L2(r_patch,r_masks)\n",
    "    \n",
    "            fake=Gen_model(x)\n",
    "          \n",
    "\n",
    "            #fake_patch\n",
    "            f_patch = Disc(fake.detach(),x)\n",
    "            # print(f_patch.shape,f_masks.shape)\n",
    "            \n",
    "            f_disc_loss=L2(f_patch,f_masks)\n",
    "            Disc_loss = r_disc_loss + f_disc_loss\n",
    "            \n",
    "            Disc_loss.backward()\n",
    "            Disc_optim.step()\n",
    "    \n",
    "            # gen\n",
    "            Gen_model.zero_grad()\n",
    "            f_patch = Disc(fake,x)\n",
    "            f_gan_loss=L2(f_patch,r_masks)\n",
    "\n",
    "            L1_loss = L1(fake,y)\n",
    "            Gen_loss = f_gan_loss + L1_lambda*L1_loss\n",
    "            \n",
    "            Gen_loss.backward()\n",
    "\n",
    "            Gen_optim.step()\n",
    "            end_time = time.time()  # End measuring time for each iteration\n",
    "            elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "           \n",
    "    \n",
    "            \n",
    "        if (i+1)%iter_per_plot == 0 :\n",
    "\n",
    "            print('Epoch [{}/{}], Step [{}/{}], disc_loss: {:.4f}, gen_loss: {:.4f},Disc(real): {:.2f}, Disc(fake):{:.2f}, gen_loss_gan:{:.4f}, gen_loss_L1:{:.4f}'.format(ep+1, epochs, i+1, len(load_Train), Disc_loss.item(), Gen_loss.item(), r_disc_loss.item(), f_disc_loss.item(), f_gan_loss.item(), L1_loss.item()))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    if (ep+1)%5==0:\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            Gen_model.eval()\n",
    "            for data in load_Train:\n",
    "                # print(data.shape)\n",
    "                # x, y = split(data.to(device))\n",
    "\n",
    "                x1,y1=[],[]\n",
    "                x2,y2=[],[]\n",
    "                x3,y3=[],[]\n",
    "                x4,y4=[],[]\n",
    "                x5,y5=[],[]\n",
    "                \n",
    "                x_img, y_img= split(data.to(device))\n",
    "        \n",
    "                for img in x_img:\n",
    "                  x1.append(img[:,:128,:128])\n",
    "                  x2.append(img[:,128:,:128])\n",
    "                  x3.append(img[:,:128,128:])\n",
    "                  x4.append(img[:,128:,128:])\n",
    "                  x5.append(img[:,64:192,64:192])\n",
    "        \n",
    "                for img in y_img:\n",
    "                  y1.append(img[:,:128,:128])\n",
    "                  y2.append(img[:,128:,:128])\n",
    "                  y3.append(img[:,:128,128:])\n",
    "                  y4.append(img[:,128:,128:])\n",
    "                  y5.append(img[:,64:192,64:192])\n",
    "        \n",
    "                \n",
    "                input=[]\n",
    "        \n",
    "                input.append((torch.stack(x1),torch.stack(y1)))\n",
    "                input.append((torch.stack(x2),torch.stack(y2)))\n",
    "                input.append((torch.stack(x3),torch.stack(y3)))\n",
    "                input.append((torch.stack(x4),torch.stack(y4)))\n",
    "                input.append((torch.stack(x5),torch.stack(y5)))\n",
    "        \n",
    "                # print(input[0][0].shape)\n",
    "                output=[]\n",
    "                for x,y in input:\n",
    "                    fake = Gen_model(x)\n",
    "                    output.append(fake)\n",
    "\n",
    "\n",
    "\n",
    "                fake_img=torch.zeros(30,3,256,256)\n",
    "\n",
    "                fake_img[:,:,:128,:128]=output[0]\n",
    "\n",
    "                fake_img[:,:,128:,:128]=output[1]\n",
    "\n",
    "                fake_img[:,:,:128,128:]=output[2]\n",
    "\n",
    "                fake_img[:,:,128:,128:]=output[3]\n",
    "\n",
    "                fake_img[:,:,64:192,64:192]=output[4]\n",
    "            \n",
    "                    \n",
    "                for j in range(fake_img.shape[0]):\n",
    "                    if j%10==0:\n",
    "                        figs=plt.figure(figsize=(10,10))\n",
    "            \n",
    "                        plt.subplot(1,3,1)\n",
    "                        plt.axis(\"off\")\n",
    "                        plt.title(\"input image\")\n",
    "                        plt.imshow(np.transpose(vutils.make_grid(x_img[j], nrow=1, padding=5,\n",
    "                        normalize=True).cpu(), (1,2,0)))\n",
    "                    \n",
    "                        plt.subplot(1,3,2)\n",
    "                        plt.axis(\"off\")\n",
    "                        plt.title(\"generated image\")\n",
    "                        plt.imshow(np.transpose(vutils.make_grid(fake_img[j], nrow=1, padding=5,\n",
    "                        normalize=True).cpu(), (1,2,0)))\n",
    "                    \n",
    "                        plt.subplot(1,3,3)\n",
    "                        plt.axis(\"off\")\n",
    "                        plt.title(\"ground truth\")\n",
    "                        plt.imshow(np.transpose(vutils.make_grid(y_img[j], nrow=1, padding=5,\n",
    "                        normalize=True).cpu(), (1,2,0)))\n",
    "    \n",
    "                break\n",
    "            Gen_model.train()\n",
    "            \n",
    "    if ep+1==epochs:\n",
    "        torch.save(Gen_model.state_dict(), 'patchmodel.pth')  # for saving the model after training\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####visualsing the generated image and plotting the error map\n",
    "\n",
    "batch_size = 1  # Set the batch size to 1 to get a single image in each iteration\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "c=0\n",
    "\n",
    "generator.load_state_dict(torch.load('patchmodel.pth', map_location=device)) # calling the saved model\n",
    "\n",
    "for i,data in enumerate (test_loader):\n",
    "    if i%10==0:\n",
    "        c+=1\n",
    "        t_batch=data['image1'] # loading input and target \n",
    "        with torch.no_grad():\n",
    "            generator.eval()\n",
    "            x1,y1=[],[]\n",
    "            x2,y2=[],[]\n",
    "            x3,y3=[],[]\n",
    "            x4,y4=[],[]\n",
    "            x5,y5=[],[]\n",
    "                \n",
    "            x_img, y_img= split(t_batch.to(device))\n",
    "        \n",
    "            for img in x_img:\n",
    "              x1.append(img[:,:128,:128])\n",
    "              x2.append(img[:,128:,:128])\n",
    "              x3.append(img[:,:128,128:])\n",
    "              x4.append(img[:,128:,128:])\n",
    "              x5.append(img[:,64:192,64:192])\n",
    "    \n",
    "            for img in y_img:\n",
    "              y1.append(img[:,:128,:128])\n",
    "              y2.append(img[:,128:,:128])\n",
    "              y3.append(img[:,:128,128:])\n",
    "              y4.append(img[:,128:,128:])\n",
    "              y5.append(img[:,64:192,64:192])\n",
    "    \n",
    "            \n",
    "            input=[]\n",
    "    \n",
    "            input.append((torch.stack(x1),torch.stack(y1)))\n",
    "            input.append((torch.stack(x2),torch.stack(y2)))\n",
    "            input.append((torch.stack(x3),torch.stack(y3)))\n",
    "            input.append((torch.stack(x4),torch.stack(y4)))\n",
    "            input.append((torch.stack(x5),torch.stack(y5)))\n",
    "    \n",
    "            # print(input[0][0].shape)\n",
    "            output=[]\n",
    "            \n",
    "            for x,y in input:\n",
    "                # print(x.shape)\n",
    "                fake =generator(x)\n",
    "                output.append(fake)\n",
    "\n",
    "            fake_img=torch.zeros(1,3,256,256)\n",
    "\n",
    "            fake_img[:,:,:128,:128]=output[0]\n",
    "\n",
    "            fake_img[:,:,128:,:128]=output[1]\n",
    "\n",
    "            fake_img[:,:,:128,128:]=output[2]\n",
    "\n",
    "            fake_img[:,:,128:,128:]=output[3]\n",
    "\n",
    "            fake_img[:,:,64:192,64:192]=output[4]\n",
    "    \n",
    "            \n",
    "            \n",
    "            figs=plt.figure(figsize=(10,10))\n",
    "\n",
    "            plt.subplot(1,4,1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"input image\")\n",
    "            \n",
    "            plt.imshow(np.rot90(np.transpose(vutils.make_grid(x_img[0], nrow=1, padding=5,\n",
    "            normalize=True).cpu(), (1,2,0)),k=-1))\n",
    "            \n",
    "            \n",
    "            plt.subplot(1,4,2)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"generated image\")\n",
    "            plt.imshow(np.rot90(np.transpose(vutils.make_grid(fake_img[0], nrow=1, padding=5,\n",
    "            normalize=True).cpu(), (1,2,0)),k=-1))\n",
    "            # plt.colorbar()\n",
    "            \n",
    "            plt.subplot(1,4,3)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"ground truth\")\n",
    "            plt.imshow(np.rot90(np.transpose(vutils.make_grid(y_img[0], nrow=1, padding=5,\n",
    "            normalize=True).cpu(), (1,2,0)),k=-1))\n",
    "            # plt.colorbar()\n",
    "            # print(t_y[j].is_cuda)\n",
    "            # print(fk[j].is_cuda)\n",
    "            plt.subplot(1,4,4)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"error map\")\n",
    "    \n",
    "            fake_img=fake_img.to(device)\n",
    "            data_eg=np.transpose(np.abs((y_img[0]-fake_img[0]).cpu().numpy()),(1,2,0))\n",
    "            normalized_data=Normalize()(data_eg)\n",
    "            normalized_data=np.mean(normalized_data, axis=2, keepdims=True)\n",
    "            # print(normalized_data.shape)\n",
    "            plt.imshow(np.rot90((normalized_data),k=-1),cmap='jet')\n",
    "\n",
    "            if c==20:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_psnr(true_image, fake_image, data_range):\n",
    "    mse = np.mean((true_image - fake_image) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 20 * np.log10(data_range / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "error_list = []\n",
    "structural_similarity_list = []\n",
    "psnr_list = []\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    t_batch = data['image1']\n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        x1, y1 = [], []\n",
    "        x2, y2 = [], []\n",
    "        x3, y3 = [], []\n",
    "        x4, y4 = [], []\n",
    "        x5, y5 = [], []\n",
    "            \n",
    "        x_img, y_img = split(t_batch.to(device))\n",
    "    \n",
    "        for img in x_img:\n",
    "            x1.append(img[:, :128, :128])\n",
    "            x2.append(img[:, 128:, :128])\n",
    "            x3.append(img[:, :128, 128:])\n",
    "            x4.append(img[:, 128:, 128:])\n",
    "            x5.append(img[:, 64:192, 64:192])\n",
    "\n",
    "        for img in y_img:\n",
    "            y1.append(img[:, :128, :128])\n",
    "            y2.append(img[:, 128:, :128])\n",
    "            y3.append(img[:, :128, 128:])\n",
    "            y4.append(img[:, 128:, 128:])\n",
    "            y5.append(img[:, 64:192, 64:192])\n",
    "\n",
    "        inputs = [\n",
    "            (torch.stack(x1), torch.stack(y1)),\n",
    "            (torch.stack(x2), torch.stack(y2)),\n",
    "            (torch.stack(x3), torch.stack(y3)),\n",
    "            (torch.stack(x4), torch.stack(y4)),\n",
    "            (torch.stack(x5), torch.stack(y5))\n",
    "        ]\n",
    "\n",
    "        outputs = []\n",
    "        \n",
    "        for x, y in inputs:\n",
    "            fake = generator(x)\n",
    "            outputs.append(fake)\n",
    "\n",
    "        fake_img = torch.zeros_like(t_batch)\n",
    "\n",
    "        fake_img[:, :, :128, :128] = outputs[0]\n",
    "        fake_img[:, :, 128:, :128] = outputs[1]\n",
    "        fake_img[:, :, :128, 128:] = outputs[2]\n",
    "        fake_img[:, :, 128:, 128:] = outputs[3]\n",
    "        fake_img[:, :, 64:192, 64:192] = outputs[4]\n",
    "        \n",
    "    t_y_numpy = y_img.cpu().detach().numpy()\n",
    "    fk_batch_numpy = fake_img.cpu().detach().numpy()\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((t_y_numpy - fk_batch_numpy) ** 2))\n",
    "    error_list.append(rmse)\n",
    "    \n",
    "    # Calculate SSIM\n",
    "    t_y_numpy = np.transpose(t_y_numpy.squeeze(), (1, 2, 0))\n",
    "    fk_batch_numpy = np.transpose(fk_batch_numpy.squeeze(), (1, 2, 0))\n",
    "    ssi = ssim(t_y_numpy, fk_batch_numpy, multichannel=True, win_size=3, data_range=2.0)\n",
    "    structural_similarity_list.append(ssi)\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    psnr_value = calculate_psnr(t_y_numpy, fk_batch_numpy, data_range=255.0)\n",
    "    psnr_list.append(psnr_value)\n",
    "\n",
    "# Convert lists to numpy arrays for statistics calculation\n",
    "error_list = np.array(error_list)\n",
    "structural_similarity_np = np.array(structural_similarity_list)\n",
    "psnr_np = np.array(psnr_list)\n",
    "\n",
    "# Print statistics\n",
    "print('Mean RMSE error:', np.mean(error_list))\n",
    "print('Max RMSE error:', np.max(error_list))\n",
    "print('Min RMSE error:', np.min(error_list))\n",
    "print('Mean SSIM:', np.mean(structural_similarity_np))\n",
    "print('Min SSIM:', np.min(structural_similarity_np))\n",
    "print('Max SSIM:', np.max(structural_similarity_np))\n",
    "print('Mean PSNR:', np.mean(psnr_np))\n",
    "print('Min PSNR:', np.min(psnr_np))\n",
    "print('Max PSNR:', np.max(psnr_np))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
